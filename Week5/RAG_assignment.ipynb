{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c4d078-0116-4c1a-9a5e-cd3b639cbab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Assignment: Create a retrieval augmented chain to accept search terms and return results from your vector db or in memory dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf229af0-e0ba-4607-8059-cff031b451a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting langchain==0.3.0\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 16.3 MB/s eta 0:00:00\n",
      "Collecting langchain-chroma==0.1.4\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Collecting langchain-community==0.3.0\n",
      "  Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 54.5 MB/s eta 0:00:00\n",
      "Collecting langchain-core==0.3.0\n",
      "  Downloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 405.1/405.1 kB 38.7 MB/s eta 0:00:00\n",
      "Collecting langchain-huggingface==0.1.0\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Collecting langchain-text-splitters==0.3.0\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 19.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (3.9.1)\n",
      "Collecting pydantic<3.0.0,>=2.7.4\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 457.0/457.0 kB 45.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (2.28.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (1.4.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (1.23.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (8.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.3.0) (6.0)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.8/311.8 kB 32.4 MB/s eta 0:00:00\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0\n",
      "  Downloading chromadb-0.5.21-py3-none-any.whl (628 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 628.3/628.3 kB 52.5 MB/s eta 0:00:00\n",
      "Collecting fastapi<1,>=0.95.2\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.8/94.8 kB 15.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /databricks/python3/lib/python3.10/site-packages (from langchain-community==0.3.0) (0.6.3)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /databricks/python3/lib/python3.10/site-packages (from langchain-core==0.3.0) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from langchain-core==0.3.0) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /databricks/python3/lib/python3.10/site-packages (from langchain-core==0.3.0) (1.33)\n",
      "Collecting transformers>=4.39.0\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.0/10.0 MB 80.9 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 447.6/447.6 kB 40.5 MB/s eta 0:00:00\n",
      "Collecting sentence-transformers>=2.6.0\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 32.7 MB/s eta 0:00:00\n",
      "Collecting tokenizers>=0.19.1\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 77.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.1)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 68.1 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 278.6/278.6 kB 32.5 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.65.0\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 12.0 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.2/93.2 kB 14.9 MB/s eta 0:00:00\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.4/242.4 kB 27.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typer>=0.9.0 in /databricks/python3/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.9.0)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.8/118.8 kB 16.4 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.3/64.3 kB 11.7 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 76.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-resources in /databricks/python3/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.1.1)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 97.5 MB/s eta 0:00:00\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.8/54.8 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.3/67.3 kB 12.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chroma-hnswlib==0.7.6\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 67.3 MB/s eta 0:00:00\n",
      "Collecting tokenizers>=0.19.1\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 57.6 MB/s eta 0:00:00\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting orjson>=3.9.12\n",
      "  Downloading orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.3/131.3 kB 20.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx>=0.27.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.28.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (3.20.2)\n",
      "Collecting starlette<0.42.0,>=0.40.0\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.2/73.2 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (2023.6.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /databricks/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.0) (2.4)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 kB 7.6 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.1\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 74.2 MB/s eta 0:00:00\n",
      "Collecting python-dotenv>=0.21.0\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.0) (2.0.4)\n",
      "Requirement already satisfied: scipy in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.10.0)\n",
      "Requirement already satisfied: Pillow in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (9.4.0)\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /databricks/python3/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.0.1+cpu)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (2.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /databricks/python3/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface==0.1.0) (2022.7.9)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /databricks/python3/lib/python3.10/site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.0.1)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /databricks/python3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.21.0)\n",
      "Requirement already satisfied: requests-oauthlib in /databricks/python3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.1)\n",
      "Collecting durationpy>=0.7\n",
      "  Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 12.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /databricks/python3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.58.0)\n",
      "Requirement already satisfied: protobuf in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.24.0)\n",
      "Requirement already satisfied: flatbuffers in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (23.5.26)\n",
      "Requirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.11.1)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting deprecated>=1.2.6\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /databricks/python3/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.62.0)\n",
      "Collecting opentelemetry-proto==1.28.2\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 6.4 MB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.7/319.7 kB 38.5 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation==0.49b2\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.2/159.2 kB 21.7 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.14.1)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 61.1 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 8.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.8.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.0) (0.4.3)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 77.6 MB/s eta 0:00:00\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.6/442.6 kB 42.7 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.2/168.2 kB 20.9 MB/s eta 0:00:00\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.1/442.1 kB 27.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.2.8)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.7/221.7 kB 27.8 MB/s eta 0:00:00\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 15.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.4.8)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=932b6ffe6645b22083561293e5bf20171298d21ca38c1749149b89a741d8f909\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/41/b6/f76a356f0791da799545c23894ceae842eeff054d0eb1fb626\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, zipp, websockets, uvloop, uvicorn, tqdm, tenacity, python-dotenv, pyproject_hooks, pypdf, pygments, pydantic-core, protobuf, overrides, orjson, opentelemetry-util-http, oauthlib, mmh3, mdurl, humanfriendly, httptools, grpcio, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, annotated-types, watchfiles, starlette, requests-toolbelt, pydantic, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface-hub, googleapis-common-protos, coloredlogs, build, tokenizers, rich, pydantic-settings, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, langsmith, kubernetes, fastapi, transformers, opentelemetry-semantic-conventions, langchain-core, sentence-transformers, opentelemetry-sdk, opentelemetry-instrumentation, langchain-text-splitters, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-huggingface, langchain, opentelemetry-instrumentation-fastapi, langchain-community, chromadb, langchain-chroma\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.11.0\n",
      "    Not uninstalling zipp at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'zipp'. No files were found to uninstall.\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Not uninstalling tqdm at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'tqdm'. No files were found to uninstall.\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.1.0\n",
      "    Not uninstalling tenacity at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'tenacity'. No files were found to uninstall.\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Not uninstalling pygments at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'Pygments'. No files were found to uninstall.\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.0\n",
      "    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.0\n",
      "    Not uninstalling oauthlib at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'oauthlib'. No files were found to uninstall.\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.2\n",
      "    Not uninstalling grpcio at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'grpcio'. No files were found to uninstall.\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Not uninstalling bcrypt at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'bcrypt'. No files were found to uninstall.\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.6\n",
      "    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'pydantic'. No files were found to uninstall.\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Not uninstalling importlib-metadata at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.4\n",
      "    Not uninstalling huggingface-hub at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'huggingface-hub'. No files were found to uninstall.\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.62.0\n",
      "    Not uninstalling googleapis-common-protos at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'googleapis-common-protos'. No files were found to uninstall.\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Not uninstalling tokenizers at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'tokenizers'. No files were found to uninstall.\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.79\n",
      "    Not uninstalling langsmith at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'langsmith'. No files were found to uninstall.\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.1\n",
      "    Not uninstalling transformers at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'transformers'. No files were found to uninstall.\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.0.13\n",
      "    Not uninstalling langchain-core at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'langchain-core'. No files were found to uninstall.\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Not uninstalling sentence-transformers at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'sentence-transformers'. No files were found to uninstall.\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.348\n",
      "    Not uninstalling langchain at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4a418cd1-c36e-4667-be93-30d07b842bb0\n",
      "    Can't uninstall 'langchain'. No files were found to uninstall.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "databricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\n",
      "ydata-profiling 4.2.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.10.3 which is incompatible.\n",
      "tensorflow-cpu 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
      "tensorboard-plugin-profile 2.14.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.29.0 which is incompatible.\n",
      "mlflow-skinny 2.9.2 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.5.0 which is incompatible.\n",
      "mlflow-skinny 2.9.2 requires protobuf<5,>=3.12.0, but you have protobuf 5.29.0 which is incompatible.\n",
      "google-api-core 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.29.0 which is incompatible.\n",
      "databricks-feature-engineering 0.2.1 requires protobuf<5,>=3.12.0, but you have protobuf 5.29.0 which is incompatible.\n",
      "Successfully installed annotated-types-0.7.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.21 coloredlogs-15.0.1 deprecated-1.2.15 durationpy-0.9 fastapi-0.115.6 googleapis-common-protos-1.66.0 grpcio-1.68.1 httptools-0.6.4 huggingface-hub-0.26.3 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-31.0.0 langchain-0.3.0 langchain-chroma-0.1.4 langchain-community-0.3.0 langchain-core-0.3.0 langchain-huggingface-0.1.0 langchain-text-splitters-0.3.0 langsmith-0.1.147 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.28.2 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 opentelemetry-util-http-0.49b2 orjson-3.10.12 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.0 pydantic-2.10.3 pydantic-core-2.27.1 pydantic-settings-2.6.1 pygments-2.18.0 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 rich-13.9.4 sentence-transformers-3.3.1 starlette-0.41.3 tenacity-8.5.0 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.46.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1 zipp-3.21.0\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.0 langchain-chroma==0.1.4 langchain-community==0.3.0 langchain-core==0.3.0 langchain-huggingface==0.1.0 langchain-text-splitters==0.3.0 pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7567400c-09f2-420e-96ce-5daa9778035e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17482c60-d18a-49c1-888f-129c6e0fd266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e499d628-e3c4-42e3-be41-519dbfe8d70a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Set Up models & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "479896e9-f8f4-4db0-87ee-d275133019d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN \"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d91c6e-24e1-4330-8c79-2d0af45ef056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Chroma vector store\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    ")\n",
    "\n",
    "# Create the LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.environ.get(\"HUGGINGFACEHUB_API_TOKEN \"),\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    temperature=0.01,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat_llm = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5cb532d-9974-4a69-9220-0773a05ef36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Adding document corpus to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bccefbe-18b7-4de9-848d-268dc994da9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def get_docs(path):\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages = loader.load_and_split()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a36bf66-fc8c-48ec-a516-cf307024448d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for i in dbutils.fs.ls(\"/Volumes/dbx_genai_classroom/rag/retreival_docs/\"):\n",
    "    if \"vision_transformers\" not in i.path and i.path.endswith(\"pdf\"):\n",
    "        docs += get_docs(i.path.replace('dbfs:', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fec916-2af4-4f8f-b6f2-9cac22234609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497d7733-9e9a-44b7-a2fb-31cc3cf3cb52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=f\"ArunachalPradesh\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a53def33-e740-41ce-955b-90c04b92e2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Note**: Run this cell only once to initialize the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6375420-35f9-4bf5-997e-0f4cd51d398f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['874a78b8-79bc-4411-b0df-253382805976',\n",
       " 'c12b7374-0d8f-4635-aab4-f5a4059f591a',\n",
       " '5e3a8205-5380-4a94-9e4a-b676b2b5fca8',\n",
       " '57fcd5ea-a459-4152-aa4d-ae6cc1ab65e9',\n",
       " '0cb2ce17-267e-4b49-8dc7-f1572651f718',\n",
       " '45a733ce-8a05-48ef-b45c-68d743f0db4d',\n",
       " '5a0eba32-9fc5-4727-a177-348d3749e6b5',\n",
       " '7f52c70f-5f7e-404c-aa9e-0e967dfd1be5',\n",
       " 'f288bef9-c414-432d-a2bf-6f424cba4b6d',\n",
       " '1bc51fb9-786c-403e-8601-88caff7f3f45',\n",
       " '2fbe3392-cee1-42c7-a2b9-56a888a692aa',\n",
       " '24180e8e-3a79-4483-b775-f1635ad05822',\n",
       " 'b28fcbbc-c1b0-49f6-855c-8fb558aa64df',\n",
       " '5e6c3174-5bee-4bf4-9f61-dd514ffe7a81',\n",
       " '40f3bef7-52ba-4491-a9d8-876c24d4833b',\n",
       " 'd4f78d3e-697b-47bf-bb2a-923da2878c22',\n",
       " 'cd59d17d-d8e8-4061-8481-beb61c3a79b8',\n",
       " '55eaea13-1cce-48bd-907e-45b37e7ba663',\n",
       " '479da038-570c-4eea-9f1e-3865f76a2c6a',\n",
       " '6e842c0a-7334-466d-b608-d5fbe2a372c6',\n",
       " '04bca22e-dce8-4806-b998-d857db22c8da',\n",
       " '3fd20bb2-f19d-4b30-977c-4223088f1f9e',\n",
       " 'a0f9e88e-59d7-41eb-977a-464b9fe77de8',\n",
       " '3de6a62c-dd08-48f8-a879-5d011cb446fe',\n",
       " '459dc528-4f51-4c04-84d8-b0d1f51c4145',\n",
       " 'a135b96a-abe2-4fd3-8c42-864f46a0dcb8',\n",
       " '31d3dc03-3372-48ce-b78e-a92c3df10e5e',\n",
       " '6120b13e-5c3b-4c17-aa42-09f9fd5b4bb2',\n",
       " '5e6909c9-59dd-41a2-859c-470e921851e1',\n",
       " '44697d90-d672-4cea-8b51-0b1b0215ed89',\n",
       " '903e8190-cef3-48cd-8dd4-642e97f8b83a',\n",
       " 'a4891d4b-720b-4b3d-a3d7-0356791aba57',\n",
       " '7f2ed07d-507b-4a83-b6f4-3faa26949545',\n",
       " 'dd972f63-013f-44a1-b53e-edd4b2b5332a',\n",
       " 'c0cea559-8700-4a7e-951e-29f5b86ae16d',\n",
       " '3befb71a-3434-4b88-b262-3474b478d2d0',\n",
       " '983b5dd3-55c6-4559-b5e3-9b443f552f56',\n",
       " '18cf81ed-d8b5-4b4a-abef-300ff519668a',\n",
       " '9e59f513-6c71-48f5-8097-a3b3a2514986',\n",
       " '29380abc-a5f3-44ce-9f98-542454bf0163',\n",
       " 'cd46964a-c977-4165-bbd1-49c5debcc179',\n",
       " 'edeadb0a-6b9c-4752-b304-8547411bce32',\n",
       " 'd5c0c32f-78b0-4482-8c5f-2eb027d68579',\n",
       " '98336ecf-83ea-46f1-bd05-9a521119ed2d',\n",
       " 'bfb855d8-8c6e-435e-b4cb-dc1a7e51dc60',\n",
       " '351ea317-bcb7-4e2f-9826-a0d3552c1166',\n",
       " 'ac61fd1d-9237-4c0d-b0d2-64aed35ac6d2',\n",
       " '0a78080b-b8dd-4111-b7b6-383c81117d15',\n",
       " 'c5551a88-138f-4e56-bdab-6c93ccfd9980',\n",
       " '575d5a09-b6b7-4f3e-8123-20c2cf2c9d3d',\n",
       " 'ab06081f-7fa6-4180-b392-9497bacf6ce2',\n",
       " '9e073604-b181-452d-af2e-ef632b9f09a1',\n",
       " '35866db7-f759-405c-a41b-3b91b6f395b5',\n",
       " 'ccf5752a-e8f2-4341-9cf8-065c56f5b5c6',\n",
       " '09703a4f-ea4b-4a33-9bf8-f807599f4f19',\n",
       " 'bfec6389-c50c-4bec-85f0-6613864bfbf8',\n",
       " 'f1453a68-a0f2-434e-a539-8b59a6d98505',\n",
       " 'ca0cd692-3e08-42e4-912a-fcbf9513eb5c',\n",
       " '53c0bd81-0f9b-4ee8-b49e-a253494b99ab',\n",
       " 'b062b080-2348-4ac2-bf8d-184b35f72523',\n",
       " 'faca363f-af83-403a-905a-e23a932ceb07',\n",
       " '8c929b88-1a58-430a-ab2d-f6c8582319be',\n",
       " '3f057637-56ef-4bb0-907e-33cdc888bba7',\n",
       " '1e206295-2fae-4506-b7f6-e5b3c44e7820',\n",
       " '61ce947f-8dfe-4c28-816a-b35e8f615a96',\n",
       " '7b63c20a-8a7c-4f5f-9221-130100ca15d1',\n",
       " 'f9da3267-628b-4f68-a978-1b613a1f7885',\n",
       " '4740aa95-d3b1-40b5-ae0f-188bc011ce0b',\n",
       " '8d4a953b-6f59-4bfa-85de-32bae4105181',\n",
       " 'cbca2be2-0deb-42b3-9954-e2f7e51a7e2e',\n",
       " '9b609078-f950-4ba5-8017-fb5887bb12d1',\n",
       " '0fc263af-d3b9-46b3-9111-e54d8a90d9ee',\n",
       " '1e96dabd-f30c-43b0-95c5-daec12ea9622',\n",
       " '083de83f-82a6-4ab2-8744-a2ec6674eefa',\n",
       " '0180a21a-7d58-4936-b45a-20e8dd8a493b',\n",
       " '91823b8a-d5e3-47a8-9081-53c3a1d65d95',\n",
       " 'caa1e11b-25b0-44af-a2fa-c4b44441a852',\n",
       " 'ca8b9099-b5c6-47f2-bfa8-d36319bada14',\n",
       " 'bea5763c-fc65-4a3d-9031-270d9203b27e',\n",
       " '4780f5a6-a429-4395-8ffa-0f65192fb80f',\n",
       " 'f960288b-ef76-408b-a8b8-8fc9fb3105a2',\n",
       " '680c0d06-958b-4804-9583-33edc6eeedc3',\n",
       " 'e596bf9e-d7ff-4bcb-9a3b-11b5fb1608a1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d7decc-ae47-4d6f-9ffe-4e5174435846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Augemented Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14e3cfdd-38fc-4dd1-b4ad-de7ee455d309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb3a5303-0cbc-48df-99b9-4ad03dc8a645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Retriever\n",
      "Created History aware Retriever\n",
      "Created RAG Chain\n"
     ]
    }
   ],
   "source": [
    "# Contextualize question #\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate one standalone question which can be understood \"\n",
    "    \"without the chat history. Ensure not to loose the semantic & syntactic meaning of the question.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "print(\"Initialized Retriever\")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    chat_llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "print(\"Created History aware Retriever\")\n",
    "\n",
    "# Answer question #\n",
    "system_prompt = (\n",
    "    \"You are an expert on the state of Arunchal Pradesh adept at question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever, question_answer_chain\n",
    ")\n",
    "\n",
    "print(\"Created RAG Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75f4d032-4603-4604-9c67-4bb2053c2360",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "549f0e14-44a3-4c05-8149-e7d1fc8f1640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2d479d-8f89-4a14-8885-72f7b0e2088b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generated_content = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are the primary animals found in Arunchal Pradesh?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"uniqueid001\"},\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RAG_assignment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
